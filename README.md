# mit-6.9101
D-TILE: Design-Thinking, Innovation and Leadership for Engineers

## 1. Innovation Process: Overview

* **Why Use an Innovation Process?**
    * To easily remember important steps
    * To have a shared language with your team
    * Process produces consistently good outcomes
    * Prevents "Inventor's Block"
* This process works for products, services, processes, policy, and everything else.

---

### 1.1. Invention vs Innovation

* **Invention**: Creating Something New
* **Innovation**: Value Capture

---

### 1.2. 12 Steps

The 12-Step Innovation Process is grouped into phases:

**Discover and Define**
1.  Problem Space Definition
2.  Needs & Assumptions Analysis
3.  Research & Discovery
4.  Stakeholder Analysis
5.  Boundary & Hazard Mitigation
6.  Specify Desired Outcomes

**Explore and Explain**
7.  Concept Generation
8.  Concept Downselection
9.  Concept Articulation

**Make and Measure**
10. Uncertainty Identification
11. Uncertainty Reduction

**Final Step**
12. Launch, Iterate, or Stop

---

### 1.3. Innovation: A Design-Consultant's View

* Innovation can be seen as the intersection of:
    * **Technology** (Feasibility)
    * **Business** (Viability)
    * **People** (Desirability)
* The D-TILE (Blade Kotelly Inc.) model adds a fourth component:
    * **Culture** (Relevancy)

---

## 2. Discover & Define

### 2.1. Needs & Assumptions Analysis

* **Purpose**:
    * Understand the needs we want to satisfy.
    * Identify areas that we assume can't be challenged or haven't been challenged.
    * Use this information to explore opportunities for innovation.

#### Needs Analysis

* What are the needs of the **customer/user**?
* What are the needs of our **company/team**?

#### Innovation Assumptions

* An Innovation Assumption is something we may have not considered improving or changing, or which hasn’t changed in a long time.
* These assumptions provide opportunities for exploration.

---

### 2.2. Research & Discovery

#### Common Research Methods

* Ethnographic (participant observation)
* Surveys/interviews/feedback analysis
* Expert analysis
* Architecture analysis
* Patent/literature review
* Meta-analysis
* Eye tracking/electroencephalography (EEG)

#### Morphological Analysis

* Learn about your problem space by comparing similar solutions and dissimilar solutions (analogs).
* Choose relevant **objective** and **subjective** criteria.
* Look for patterns and draw interesting conclusions from the analysis.

**Morphological Analysis Template**

| Competitors | Feature 1 | Feature 2 | Feature 3 | F... |
| :--- | :---: | :---: | :---: | :---: |
| **Product 1** | • | | • | |
| **Product 2** | • | • | | |
| **Product 3** | | • | • | |
| **Analog 1** | • | | | • |

---

### 2.3. Stakeholder Analysis

#### Definition & Reason

* **Definition**: A stakeholder is a person or group that has an investment, share, or interest in something.
* **Why Analyze**:
    * Establishes a global perspective (Systems Thinking).
    * Helps make good decisions, tradeoffs, and establish priorities.
    * Not all stakeholders benefit positively (e.g., the person being shot by a Nerf Blaster is a stakeholder).

#### 4 Groups

1.  **Suppliers**: Provide resources needed to create & deliver the solution.
2.  **Users / Directly Affected**: Use the solution or are directly affected by it.
3.  **Transformers**: Involved in the creation, delivery, or execution of the solution.
4.  **Approvers / Blockers & Concerned**: Can prevent creation/delivery, or may be concerned about indirect effects.

#### Ranking Stakeholders

**Stakeholder Ranking Template**

| Stakeholder | Why We Care About Them | Not Prioritized | Low | Med | High | What They Care About/How To Satisfy |
| :--- | :--- | :---: | :---: | :---: | :---: | :--- |
| *[List stakeholder]* | *[Value they provide or need from us]* | | | | | *[Their primary goals, concerns, needs]* |
| | | | | | | |
| | | | | | | |

---

### 2.4. Boundary & Hazard Mitigation

#### Identification & Mitigation

* **Identification**:
    * Identify what you are (or might be) limited by (**boundaries**).
    * Identify what could go wrong (**hazards**).
* **Mitigation**:
    * Identify boundary mitigation strategies.
    * Identify hazard mitigation strategies.

#### Ranking Boundaries & Hazard

* Assign **Likelihood** (chance it happens) and **Severity** (how bad it is if it happens) ratings.
* Calculate **Expected Impact** by multiplying Likelihood x Severity.
* Determine mitigation strategies and their cost-effectiveness.

**Boundary/Hazard Ranking Template**

| Boundary/Hazard | Likelihood (0-10) | Severity (0-10) | Expected Impact (= Likelihood x Severity) | Mitigation Strategy | Cost-Effectiveness |
| :--- | :---: | :---: | :---: | :--- | :---: |
| *[List boundary/hazard]* | | | | *[How to prevent/reduce it]* | *[High/Med/Low]* |
| | | | | | |
| | | | | | |

#### Considerations

* When identifying boundaries and hazards, consider:
    * Resources
    * Operation/Use
    * Creation, Delivery, Execution
    * Externalities

---

### 2.5. Specify Desired Outcomes

* Desired outcomes define **what** must happen, not **how** it is reached.

#### Methods in Corporations

* MRD (Market Requirements Document)
* PRD (Product Requirements Document)
* Manufacturing specification

#### Desired Outcomes for Innovations

1.  **Intellectual objectives**: Appeals to the rational mind (e.g., "make the hospital more money").
2.  **Emotional objectives**: Appeals to feelings (e.g., "make patients happier").
3.  **Success criteria & goals**: Objective and subjective measurements (e.g., "90% of operators complete the task in < 3 mins").

**Desired Outcomes Template**

| Objective | Objective Type | How Will You Measure Success? |
| :--- | :--- | :--- |
| *[State the goal]* | *[Intellectual / Emotional]* | *[List objective/subjective success criteria]* |
| | | |
| | | |

#### Conditions

* Outcomes should be aggressive and attainable, clear and inspiring.
* Too specific is just as bad as too vague.

---

## 3. Explore & Explain

### 3.1. Concept Generation

#### Techniques

* Open Brainstorming: Silent generation, sharing, grouping, then verbal generation.
* Mind Mapping
* Forced Relationships: Combine unrelated items to spark new ideas.
* “To”-“By”-“Using”

---

### 3.2. Concept Downselection

* Examine all ideas and eliminate as many as possible (for now).
* Score concepts against weighted criteria.
* Possible Criteria: Satisfy core user needs, low brand risk, competitive advantage, strong ROI, low resource requirements, technical feasibility.

**Concept Downselection Template**

| | | **Concept 1 (1-5)** | **Concept 2 (1-5)** |
| :--- | :---: | :---: | :---: |
| **Criteria** | **Weight** | **Score** | **Weighted** | **Score** | **Weighted** |
| *[Criteria 1]* | *[e.g., 5]* | | | | |
| *[Criteria 2]* | *[e.g., 3]* | | | | |
| *[Criteria 3]* | *[e.g., 2]* | | | | |
| **Totals** | | | **[Total]** | | **[Total]** |

---

### 3.3. Concept Articulation

* Quickly capture the essence of the concept.
* Articulate in *any* medium that explains the important aspects.
* Use this articulation to show a vision of a better future for your stakeholders.

#### Methods

* **Visual**
    * 2-D Visual Sketching
        * Analysis
        * Early Concepts
        * Structures
        * Experience Concepts
    * 3-D Visual Sketching (or Modeling)
        * Cardboard
        * CAD (Computer-Aided Design)
* **Textual Methods**
    * K-Scripts

* **Audio**
    * Audio Recordings

* **Process & Software**
    * Algorithm Sketching
        * Processes: Manufacturing, Chemical up-scaling, Line optimization at Disney World
        * Software: AI models, Database connection relationships

#### K-Script

* A textual sketching method that is easy to collaborate on and creates a compelling vision.
* Can be used for ethnographic research (capturing current state) or for articulating a new design.

**K-Script Template**

| Who | Observable Action | Unobservable Action / Notes |
| :--- | :--- | :--- |
| *[Stakeholder]* | *[What the person does, says, or sees]* | *[Internal thoughts, assumptions, team questions, design rationale]* |
| Customer | Walks into the fair ground... | In research, we found that people want these 2 options... |
| Customer | Clicks on "Buy tickets" | Is this odd if they have a coupon? |
| Kiosk | The screen shows "Number of Adults?"... | Why not show prices here too? |

---

## 4. Make & Measure

This phase is about accelerating learning to reduce uncertainty.

* **Concept**: Solution elements (features) are plotted on a 2D graph of **Importance** (y-axis) vs. **Uncertainty** (x-axis). (Note: slides reverse axes, but the concept is the product).
* **Risk**: The risk of an element is its **Importance x Uncertainty**.
* **Threshold**: A **Risk Tolerance Threshold** is set. Any element with a risk score *above* this threshold is a high priority.
* **Goal**: Run fast, inexpensive experiments (prototypes) to reduce the "Uncertainty" score for high-risk elements, moving them down below the threshold.

---

### 4.1. Uncertainty Identification

* **Risk: Importance & Uncertainty**
    1.  For each element of the solution, determine its **Importance** (e.g., critical feature vs. nice-to-have) and its **Uncertainty** (e.g., our ability to successfully develop it).
    2.  Multiply Importance by Uncertainty to determine the risk.
    3.  Determine which elements are above the risk tolerance threshold.

**Uncertainty Identification Template**

| Element Of Possible Uncertainty | Importance (1-10) | Uncertainty (1-10) | Uncertainty x Importance (Risk) |
| :--- | :---: | :---: | :---: |
| *[e.g., ML tech can provide nutrition info]* | *[e.g., 10]* | *[e.g., 8]* | *[e.g., 80]* |
| *[e.g., People will take pictures of food]* | *[e.g., 8]* | *[e.g., 6]* | *[e.g., 48]* |
| *[e.g., We can make an easy-to-use app]* | *[e.g., 8]* | *[e.g., 2]* | *[e.g., 16]* |

---

### 4.2. Uncertainty Reduction

#### Affordability

* For each uncertain element, determine the **least expensive way** to reduce uncertainty.
* *Example*: Uncertain if people want a fragrant garbage bag? Spray bags with perfume and give them to co-workers.
* Increase time, effort, and cost only when necessary.

#### Prototype

* Prototypes are versions of a whole solution or parts of it.
* **Physical** (Looks-like)
* **Operational** (Works-like)
* **Experiential** (Feels-like)

**Uncertainty Reduction Plan Template**

| Feature | Uncertainty x Importance (Risk) | Inexpensive Methods to Reduce Uncertainty |
| :--- | :---: | :--- |
| *[High-risk feature 1]* | *[e.g., 80]* | *[e.g., Ask a machine learning expert]* |
| *[High-risk feature 2]* | *[e.g., 48]* | *[e.g., Ask 5 people to take pictures of their food for 3 days and interview them]* |
| | | |

#### Usability Testing

* **Explanation**: A method to reduce uncertainty by having real users interact with a product to identify issues and areas for improvement.
* The primary goal is to identify problems, collect qualitative/quantitative data, and determine participant satisfaction.
* We want to learn:
    * Can people use it?
    * Do they enjoy using it?
    * Does the user form a correct **mental model** of the system?

**Usability Report Format Template**

| Issue # | Description | UX Severity (1-5) | Complexity to Fix (1-5) | Resolution |
| :--- | :--- | :---: | :---: | :--- |
| 1 | *[e.g., User didn't see the 'next' button...]* | *[e.g., 4 (high)]* | *[e.g., 1 (low)]* | *[e.g., consider changing button color...]* |
| 2 | | | | |
| | | | | |

#### Mental Model

* A mental model is an explanation of someone's thought process about how something works in the real world.
* It enables a person to extend knowledge from one area to another.

---

## 5. Problem Definition

* This is Step 1 of the process, revisited. "A problem well stated is a problem half-solved".

### 5.1. A Well-Defined Problem

* Makes it easy for you to understand how to solve the problem.
* Makes it easy for *others* to understand the problem and the *value* of solving it.
* Motivates people to help you create value.

---

### 5.2. Kotelly Problem Definition Structure

This structure focuses the reader on the *outcome*, not a specific solution.

* **[Affected group, "who?"]** currently **[way they currently address the situation]**.
* The reason we need to make a change is because **[motivating reason why the status quo is a problem, including consequences]**.
* Therefore, we will create a solution that enables **[affected group]** to **[experience a desired outcome]**.

---

### 5.3. 6 Common Mistakes

**Mistakes with Logic:**
1.  **Incorrectly identified affected group**: Stating a group that's part of the system but not the end-user.
2.  **Not stating the root problem**: Stating a downstream problem instead of the core issue.
3.  **Specifying the solution**: The outcome is too narrow and only allows one way to solve the problem.

**Mistakes with Articulation:**
4.  Not-stating the current approach/method **neutrally**.
5.  Not creating **clarity** about why the problem should be addressed.
6.  Not stating the **magnitude and impact** of *not* solving the problem.

---

## 6. Launch, Iterate, or Stop

* This is the 12th and final step, where a decision is made based on the "Make & Measure" phase.

### 6.1. Launch

* Assemble key information for execution teams.
* **Must-haves**: Clear problem statement and a compelling vision of the solution.
* **Supporting info**: Stakeholder analysis, risk/hazard analysis, concept articulation, prototype results, and desired outcomes.

---

### 6.2. Iterate

* Catalog all information (problem statement, research, concepts, etc.).
* Create an **SWQ analysis**:
    * What learnings were **S**uccessful?
    * What were the **W**eaknesses of the concepts?
    * What **Q**uestions should we answer in the next iteration?

---

### 6.3. Stop

* Catalog all information (same as Iterate).
* Create an **SW analysis**:
    * What learning was **S**uccessful?
    * What were the **W**eaknesses of the concepts?
* Develop a **new problem statement** to explore other valuable areas.

---

## 7. Appendix